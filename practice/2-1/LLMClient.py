import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

load_dotenv()

class HelloAgentsLLM:
    """
    LLM client for HelloAgents
    """
    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ä¸­åŠ è½½
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT", 60))

        if not all([self.model, apiKey, baseUrl]):
            raise ValueError("æ¨¡å‹çš„idã€API keyæˆ–URLåœ°å€æœªæä¾›å®Œæ•´/æœªåœ¨.envæ–‡ä»¶ä¸­è¢«å®šä¹‰")

        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def think(self, message: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å“åº”
        """
        print(f"ğŸ§ æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹")

        try:
            # response æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œä¸€ç›´åœ¨è¾“å‡º
            response = self.client.chat.completions.create(
                model=self.model,
                messages=message,
                temperature=temperature,
                stream=True
            )

            # å¤„ç†æµå¼å“åº”
            print("âœ…å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š")
            collected_content = []
            # åŒæ­¥é˜»å¡ï¼Œç›´åˆ° response ç”Ÿæˆå®Œæ¯•
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)
            print() # æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            print(f"âŒè°ƒç”¨å¤§æ¨¡å‹APIæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            return None


# --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == '__main__':
    try:
        llmClient = HelloAgentsLLM()

        exampleMessages = [
            {"role": "system", "content": "You are a helpful assistant that writes Python code."},
            {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
        ]

        print("--- è°ƒç”¨LLM ---")
        responseText = llmClient.think(exampleMessages)
        if responseText:
            print("\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---")
            print(responseText)

    except ValueError as e:
        print(e)